"""
ìŠ¤ì¼€ì¼ë§ ì—†ì´ ëª¨ë¸ í•™ìŠµ
StandardScaler ì˜¤ë¥˜ ì™„ì „ í•´ê²°
"""
from datetime import datetime

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os


def load_and_prepare_data(filepath="./data/saju_dataset.csv"):
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ìŠ¤ì¼€ì¼ë§ ì—†ìŒ)"""
    
    print("\n=== ë°ì´í„° ë¡œë“œ ===")
    df = pd.read_csv(filepath, encoding='utf-8-sig')
    print(f"âœ… {len(df)}ê°œ ë ˆì½”ë“œ ë¡œë“œ")
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    df = df.dropna()
    
    # ì‹œê°„ ì…ë ¥ ì—¬ë¶€
    df['ì‹œê°„ì…ë ¥ì—¬ë¶€'] = (df['ì‹œ'] != -1).astype(int)
    
    # ì˜¤í–‰ ë¹„ìœ¨ ê³„ì‚°
    ohaeng_cols = ['ëª©', 'í™”', 'í† ', 'ê¸ˆ', 'ìˆ˜']
    df['ì˜¤í–‰í•©ê³„'] = df[ohaeng_cols].sum(axis=1)
    
    for col in ohaeng_cols:
        df[f'{col}_ë¹„ìœ¨'] = df[col] / df['ì˜¤í–‰í•©ê³„']
    
    # ì˜¤í–‰ ê· í˜•ë„
    df['ì˜¤í–‰ê· í˜•ë„'] = df[ohaeng_cols].std(axis=1)
    
    # ê³„ì ˆ
    def get_season(month):
        if month in [3, 4, 5]:
            return 0  # ë´„
        elif month in [6, 7, 8]:
            return 1  # ì—¬ë¦„
        elif month in [9, 10, 11]:
            return 2  # ê°€ì„
        else:
            return 3  # ê²¨ìš¸
    
    df['ê³„ì ˆ_encoded'] = df['ì›”'].apply(get_season)
    
    # ì—°ë ¹ëŒ€
    df['ì—°ë ¹ëŒ€'] = ((datetime.now().year - df['ë…„']) // 10) * 10
    
    print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    return df


def train_model_no_scaling(df, target_column='ì„±ê²©ìœ í˜•'):
    """ìŠ¤ì¼€ì¼ë§ ì—†ì´ ëª¨ë¸ í•™ìŠµ"""
    
    print(f"\n=== ëª¨ë¸ í•™ìŠµ (ëª©í‘œ: {target_column}) ===")
    
    # íŠ¹ì„± ì„ íƒ
    feature_columns = [
        'ëª©', 'í™”', 'í† ', 'ê¸ˆ', 'ìˆ˜',
        'ëª©_ë¹„ìœ¨', 'í™”_ë¹„ìœ¨', 'í† _ë¹„ìœ¨', 'ê¸ˆ_ë¹„ìœ¨', 'ìˆ˜_ë¹„ìœ¨',
        'ì˜¤í–‰ê· í˜•ë„', 'ì‹œê°„ì…ë ¥ì—¬ë¶€', 'ì—°ë ¹ëŒ€', 'ê³„ì ˆ_encoded'
    ]
    
    X = df[feature_columns]
    y = df[target_column]
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )
    
    print(f"âœ… í•™ìŠµ: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
    
    # ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ
    models = {
        "ì˜ì‚¬ê²°ì •ë‚˜ë¬´": DecisionTreeClassifier(max_depth=10, random_state=42),
        "ëœë¤í¬ë ˆìŠ¤íŠ¸": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    }
    
    best_model = None
    best_score = 0
    best_name = ""
    
    for name, model in models.items():
        print(f"\n--- {name} í•™ìŠµ ì¤‘ ---")
        
        # í•™ìŠµ
        model.fit(X_train, y_train)
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(model, X_train, y_train, cv=5)
        mean_score = cv_scores.mean()
        
        print(f"êµì°¨ ê²€ì¦ ì •í™•ë„: {mean_score:.4f} (+/- {cv_scores.std():.4f})")
        
        if mean_score > best_score:
            best_score = mean_score
            best_model = model
            best_name = name
    
    # í…ŒìŠ¤íŠ¸ í‰ê°€
    print(f"\n=== ìµœê³  ëª¨ë¸: {best_name} ===")
    y_pred = best_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_test, y_pred))
    
    return best_model, best_name, accuracy


def save_model(model, model_name):
    """ëª¨ë¸ ì €ì¥"""
    os.makedirs("./models", exist_ok=True)
    filepath = f"./models/saju_model_{model_name}.pkl"
    joblib.dump(model, filepath)
    print(f"\nâœ… ëª¨ë¸ ì €ì¥: {filepath}")
    return filepath


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("=" * 60)
    print("ğŸ§  ìŠ¤ì¼€ì¼ë§ ì—†ëŠ” ì‚¬ì£¼ ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    
    # 1. ë°ì´í„° í™•ì¸
    data_path = "./data/saju_dataset.csv"
    if not os.path.exists(data_path):
        print(f"\nâŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {data_path}")
        print("ë¨¼ì € 'python data_collector.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    try:
        # 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = load_and_prepare_data(data_path)
        
        # 3. ëª¨ë¸ í•™ìŠµ
        model, model_name, accuracy = train_model_no_scaling(df, target_column='ì„±ê²©ìœ í˜•')
        
        # 4. ì €ì¥
        model_path = save_model(model, model_name)
        
        # 5. ì™„ë£Œ
        print("\n" + "=" * 60)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {accuracy:.2%}")
        print(f"ğŸ“ ëª¨ë¸ íŒŒì¼: {model_path}")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:")
        print("  python simple_predictor.py")
        print("\në˜ëŠ” ì›¹ì•± ì‹¤í–‰:")
        print("  streamlit run app_fixed.py")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()